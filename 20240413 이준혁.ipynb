{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36da755-8a03-48a7-aa7d-739b3ef5619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# 실행 브라우저 시각화\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c029be-9497-4489-9c53-896d36c485f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 811457 entries, 0 to 811456\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   waferMap        811457 non-null  object \n",
      " 1   dieSize         811457 non-null  float64\n",
      " 2   lotName         811457 non-null  object \n",
      " 3   waferIndex      811457 non-null  float64\n",
      " 4   trianTestLabel  811457 non-null  object \n",
      " 5   failureType     811457 non-null  object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('LSWMD.pkl')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6776bcff-50bc-4c86-81c0-b0bdacb2c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center\n",
      "Donut\n",
      "Edge-Loc\n",
      "Edge-Ring\n",
      "Loc\n",
      "Near-full\n",
      "none\n",
      "Random\n",
      "Scratch\n",
      "test\n",
      "train\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "folder_path = './wm_images'\n",
    "file_list = os.listdir(folder_path)\n",
    "for file_name in file_list:\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed22d48-446c-4601-8c6e-8f3b6c29de8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172950, 25519, 147431)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['failureNum']=df.failureType      # failureType을 failureNum 변수에 입력 \n",
    "df['trainTestNum']=df.trianTestLabel # trianTestLabel을 trainTestNum 변수에 입력 (trainTestNum 데이터 자체 오타)\n",
    "\n",
    "mapping_type={\n",
    "    'Center':0,\n",
    "    'Donut':1,\n",
    "    'Edge-Loc':2,\n",
    "    'Edge-Ring':3,\n",
    "    'Loc':4,\n",
    "    'Random':5,\n",
    "    'Scratch':6,\n",
    "    'Near-full':7,\n",
    "    'none':8}\n",
    "\n",
    "mapping_traintest={'Training':0,'Test':1}\n",
    "\n",
    "df=df.replace({'failureNum':mapping_type, 'trainTestNum':mapping_traintest}) #문자를 숫자로 치환\n",
    "\n",
    "df_label = df[(df['failureNum']>=0) & (df['failureNum']<=8)]\n",
    "df_label = df_label.reset_index()\n",
    "df_pattern = df[(df['failureNum']>=0) & (df['failureNum']<=7)]\n",
    "df_pattern = df_pattern.reset_index()\n",
    "df_none = df[(df['failureNum']==8)]\n",
    "\n",
    "# 1) 불량 총 갯수, 2) 불량 패턴, 3) none\n",
    "df_label.shape[0], df_pattern.shape[0], df_none.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630157ff-9b26-4048-a927-efc61b6b2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def save_image(image_data, save_dir, image_name):\n",
    "    # 객체 생성\n",
    "    width, height = len(image_data[0]), len(image_data)\n",
    "    img = Image.new('RGB', (width, height))\n",
    "\n",
    "    # 픽셀 색상 지정\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if image_data[y][x] == 0:\n",
    "                img.putpixel((x,y), (255,255,255)) # 흰색\n",
    "            elif image_data[y][x] == 1:\n",
    "                img.putpixel((x,y), (255,200,0)) # 노랑\n",
    "            elif image_data[y][x] == 2:\n",
    "                img.putpixel((x,y), (0,50,200)) # 파랑\n",
    "\n",
    "    # 저장 디렉토리\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # 이미지 저장\n",
    "    save_path = os.path.join(save_dir, image_name)\n",
    "    img.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c79efcb-9109-45d2-bd37-667b60cc7220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center : 4294\n",
      "Donut : 555\n",
      "Edge-Loc : 5189\n",
      "Edge-Ring : 9680\n",
      "Loc : 3593\n",
      "Random : 866\n",
      "Scratch : 1193\n",
      "Near-full : 149\n"
     ]
    }
   ],
   "source": [
    "x = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "labels = ['Center','Donut','Edge-Loc','Edge-Ring','Loc','Random','Scratch','Near-full']\n",
    "\n",
    "# 불량 패턴별 총 갯수\n",
    "for j in x:\n",
    "    print('{} : {}'.format(labels[j], df_pattern.failureType[df_pattern.failureType == labels[j]].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e3345c-5db5-4412-a003-6baba970c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불량 패턴 8가지 원본 이미지 추출\n",
    "for j in x:\n",
    "    img = df_pattern.waferMap[df_pattern.failureType==labels[j]]\n",
    "    for i in range(img.shape[0] - 1):\n",
    "        image_data = img[img.index[i]]\n",
    "        save_dir = './wm_images/' + str(df_pattern.failureType[img.index[i]][0][0])\n",
    "        save_image(image_data, save_dir, 'wm_' + str(i) + '.bmp')\n",
    "\n",
    "# none 추출 (1만개만 추출하여 그대로 사용)\n",
    "img = df_none.waferMap[df_none.failureType=='none']\n",
    "for i in range(10000):\n",
    "    image_data = img[img.index[i]]\n",
    "    save_dir = './wm_images/none'\n",
    "    save_image(image_data, save_dir, 'wm_' + str(i) + '.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "731832ae-7cb1-45f7-bed1-da85f7f785fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def augment_images(save_dir, max_num_images=10000, seed=42):\n",
    "    # 데이터 증강 파라미터 설정 파이프라인 정의\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(40, fill=1), # 40도 회전\n",
    "        #transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.9, 1.0), ratio=(0.8, 1.25)),  # 크기 조정 및 크롭\n",
    "        transforms.RandomHorizontalFlip(), # 좌우 반전\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.2, 0.15), shear=0.1, scale=(0.9, 1.1), fill=1), # 이동, 전단, 스케일 변환\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)], p=0.5), # 색상 변환\n",
    "    ])\n",
    "\n",
    "    random.seed(seed)\n",
    "    image_file_list = os.listdir(save_dir)\n",
    "    random.shuffle(image_file_list)\n",
    "    max_num_augmented_images = max_num_images - len(image_file_list)\n",
    "    num_augmentations = max_num_augmented_images // len(image_file_list) + 1\n",
    "\n",
    "    i = 0\n",
    "    for file_name in image_file_list:\n",
    "        image_path = os.path.join(save_dir, file_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\") # BMP 파일을 열고 RGB로 변환\n",
    "        image = TF.to_tensor(image) # PIL 이미지를 PyTorch 텐서로 변환\n",
    "        image = transforms.Resize((224, 224))(image) # 크기 조정\n",
    "        \n",
    "        for j in range(num_augmentations):\n",
    "            augmented_image = transform(image)\n",
    "            save_path = os.path.join(save_dir, f'{file_name}d_{j}.bmp')\n",
    "            save_image(augmented_image, save_path)\n",
    "            i += 1\n",
    "            if i >= max_num_images:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10eff7b-1789-48db-a26e-37b8982fa382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스별 이미지 증량\n",
    "\n",
    "labels = ['Center','Donut','Edge-Loc','Edge-Ring','Loc','Random','Scratch','Near-full']\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    save_dir = \"./wm_images/{}\".format(labels[i])\n",
    "    augment_images(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "826df225-215a-4746-9c74-1e02a9e2d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터셋\n",
    "\n",
    "import shutil\n",
    "\n",
    "def dir_exists(save_dir):\n",
    "    # 저장될 디렉토리 생성\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "# 각 클래스별 저장 폴더들\n",
    "original_dir = './wm_images/'\n",
    "\n",
    "train_dir = './wm_images/train/'\n",
    "val_dir = './wm_images/val/'\n",
    "test_dir = './wm_images/test/'\n",
    "\n",
    "# 각 이미지 개수 설정\n",
    "train_num = 6000\n",
    "val_num = 2500\n",
    "test_num = 1500\n",
    "\n",
    "subdirs = ['Center','Donut','Edge-Loc','Edge-Ring','Loc','Random','Scratch','Near-full','none']\n",
    "\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(original_dir, subdir)\n",
    "    img_list = os.listdir(subdir_path)\n",
    "    random.shuffle(img_list) # 이미지 파일 섞기\n",
    "\n",
    "    total_imgs = len(img_list) # 실제 이미지 개수 확인\n",
    "    train_end_idx = min(train_num, total_imgs)\n",
    "    val_end_idx = min(train_end_idx + val_num, total_imgs)\n",
    "    test_end_idx = min(val_end_idx + test_num, total_imgs)\n",
    "\n",
    "    # 학습 이미지 저장\n",
    "    train_imgs = img_list[:train_num]\n",
    "    for train_img in train_imgs:\n",
    "        src = os.path.join(subdir_path, train_img)\n",
    "        dst = os.path.join(train_dir, subdir, train_img)\n",
    "        dir_exists(os.path.join(train_dir, subdir))\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "    # 검증 이미지 저장\n",
    "    val_imgs = img_list[train_num:train_num+val_num]\n",
    "    for val_img in val_imgs:\n",
    "        src = os.path.join(subdir_path, val_img)\n",
    "        dst = os.path.join(val_dir, subdir, val_img)\n",
    "        dir_exists(os.path.join(val_dir, subdir))\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy(src, dst)\n",
    "    \n",
    "\n",
    "    # 시험 이미지 저장\n",
    "    test_imgs = img_list[train_num+val_num:train_num+val_num+test_num]\n",
    "    for test_img in test_imgs:\n",
    "        src = os.path.join(subdir_path, test_img)\n",
    "        dst = os.path.join(test_dir, subdir, test_img)\n",
    "        dir_exists(os.path.join(test_dir, subdir))\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a0d3a9-280a-4ccb-b0cd-c290e8d5d631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리소스 정리\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b536799-3743-43d7-abab-056f58e0d078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "##모델 정의 이준혁)\n",
    "import sys\n",
    "sys.path.append('c:\\\\users\\\\user\\\\myenv\\\\lib\\\\site-packages')\n",
    "\n",
    "import torch.nn as nn  # nn 모듈 임포트 추가\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torch.optim as optim\n",
    "\n",
    "# 모델 정의 (EfficientNet B0)\n",
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.efficientnet._fc = nn.Linear(self.efficientnet._fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = EfficientNetB0()\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "553732df-ff37-4ce1-b565-42e4fcfb592d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNetB0(\n",
       "  (efficientnet): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6-7): 2 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9-10): 2 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12-14): 3 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (_fc): Linear(in_features=1280, out_features=9, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb23a7-edbe-483b-ad69-332801451ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 데이터셋 디렉토리\n",
    "train_dir = './wm_images/train/'\n",
    "val_dir = './wm_images/val/'\n",
    "test_dir = './wm_images/test/'\n",
    "\n",
    "# 데이터 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
    "    transforms.ToTensor(),           # PIL 이미지를 PyTorch 텐서로 변환\n",
    "])\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = ImageFolder(train_dir, transform=transform)\n",
    "val_dataset = ImageFolder(val_dir, transform=transform)\n",
    "test_dataset = ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 기존 코드와 같이 사용하도록 수정\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader,\n",
    "    'test': test_dataloader\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 기존 코드에 정확도 계산을 추가하기 위한 함수\n",
    "def calculate_accuracy(model, dataloader, device):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "    return corrects.double() / total\n",
    "\n",
    "# 학습 이력을 저장할 딕셔너리 초기화\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # 학습 단계\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # 옵티마이저의 그래디언트를 0으로 초기화\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # 역전파 단계\n",
    "        optimizer.step()  # 옵티마이저로 파라미터 업데이트\n",
    "        train_loss += loss.item() * inputs.size(0)  # 배치 손실 추가\n",
    "\n",
    "    # 검증 단계\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)  # 배치 손실 추가\n",
    "\n",
    "    # 에폭별 평균 손실 계산\n",
    "    train_loss = train_loss / len(dataloaders['train'].dataset)\n",
    "    val_loss = val_loss / len(dataloaders['val'].dataset)\n",
    "    \n",
    "    # 에폭별 정확도 계산\n",
    "    train_accuracy = calculate_accuracy(model, dataloaders['train'], device)\n",
    "    val_accuracy = calculate_accuracy(model, dataloaders['val'], device)\n",
    "\n",
    "    # 결과를 history 딕셔너리에 추가\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_accuracy'].append(train_accuracy.item())\n",
    "    history['val_accuracy'].append(val_accuracy.item())\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}, Train Acc: {train_accuracy.item()}, Val Acc: {val_accuracy.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048e002-2d32-4a53-a8a8-027b4b13aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 학습 이력 저장\n",
    "with open('train_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "# 테스트 데이터셋에 대한 평가 추가\n",
    "test_accuracy = calculate_accuracy(model, dataloaders['test'], device)\n",
    "print(f'Test Accuracy: {test_accuracy.item()}')\n",
    "\n",
    "# 모델의 가중치 저장\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "\n",
    "# 전체 모델 저장\n",
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b0c57-7576-4caa-a198-5d3dcf2a2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 그래프\n",
    "plt.plot(history['train_accuracy'], label='train accuracy')\n",
    "plt.plot(history['val_accuracy'], label='validation accuracy')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, axis='y', color='red', alpha=0.5, linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.plot(history['train_loss'], label='train loss')\n",
    "plt.plot(history['val_loss'], label='validation loss')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, axis='y', color='red', alpha=0.5, linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# 테스트 정확도 출력\n",
    "print(\"웨이퍼 탐지 모델 정확도 : {:5.2f}%\".format(100 * test_accuracy.item()))\n",
    "\n",
    "# 손실과 정확도를 동시에 보여주는 그래프\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history['train_loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history['val_loss'], 'r', label='validation loss')\n",
    "acc_ax.plot(history['train_accuracy'], 'b', label='train accuracy')\n",
    "acc_ax.plot(history['val_accuracy'], 'g', label='validation accuracy')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='lower left')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.grid(True, axis='y', color='red', alpha=0.5, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ff3a74-0a33-414b-b452-60ed37a85c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 혼동행렬 부분 (이준혁)\n",
    "import numpy as np\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score,\n",
    "                             recall_score, precision_score, f1_score)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion Matrix 시각화\n",
    "def plot_confusion_matrix(cm, target_names=None, cmap=None, normalize=True, labels=True, title='Confusion matrix'):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    \n",
    "    if labels:\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            if normalize:\n",
    "                plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "            else:\n",
    "                plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Accuracy, Precision, Recall, F-1 Socre 계산\n",
    "def calculate_cm_metrics(y_pred, y_true):\n",
    "    # Confusion Matrix 계산\n",
    "    cm = confusion_matrix(y_true, y_pred)   # 매개변수 순서 : y축, x축\n",
    "\n",
    "    # 클래스별 TP, FN, FP, TN 값 계산\n",
    "    n = cm.shape[0]\n",
    "    precision = np.zeros(n)\n",
    "    recall = np.zeros(n)\n",
    "    f1_score = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        tp = tp = cm[i, i]\n",
    "        fn = cm[i].sum() - tp\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        tn = cm.sum() - tp - fn - fp\n",
    "\n",
    "        precision[i] = tp / (tp + fp)\n",
    "        recall[i] = tp / (tp + fn)\n",
    "        f1_score[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i])\n",
    "\n",
    "    return accuracy_score(y_pred, y_true), precision, recall, f1_score\n",
    "\n",
    "# 예측값 도출\n",
    "Y_pred = model.predict_generator(test_generator, steps=test_generator.samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "# 실제값 도출\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# confusion matrix 생성\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# confusion matrix 시각화\n",
    "plot_confusion_matrix(cm, target_names=test_generator.class_indices.keys())\n",
    "\n",
    "# Accuracy, Precision, Recall, F-1 Socre 계산\n",
    "acc, prc, rcl, f1 = calculate_cm_metrics(y_pred, y_true)\n",
    "print('Accuracy = {:.2f}'.format(acc))\n",
    "print('Precision = {:.2f}'.format(prc[0]))\n",
    "print('Recall = {:.2f}'.format(rcl[0]))\n",
    "print('f1-score = {:.2f}'.format(f1[0]))\n",
    "\n",
    "# scikit-learn 활용\n",
    "print('\\nscikit-learn')\n",
    "print('Accuracy = {:.2f}'.format(accuracy_score(y_true, y_pred)))\n",
    "print('Precision = {:.2f}'.format(precision_score(y_true, y_pred, average=None)[0]))\n",
    "print('Recall = {:.2f}'.format(recall_score(y_true, y_pred, average=None)[0]))\n",
    "print('F1-score = {:.2f}'.format(f1_score(y_true, y_pred, average=None)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2975b0d6-1afb-42c7-ad37-deeb525e13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 및 예측\n",
    "\n",
    "# 모델 평가\n",
    "print(\"\")\n",
    "print(\"-- Evaluate --\")\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss = test_loss / len(dataloaders['test'].dataset)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(\"Test Loss: {:.4f}, Test Accuracy: {:.2f}%\".format(test_loss, test_accuracy))\n",
    "\n",
    "# 예측\n",
    "print(\"\")\n",
    "print(\"-- Predict --\")\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in dataloaders['test']:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807501d-240e-4d43-ac3c-2cc0a464971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# 예측값 도출 함수\n",
    "def predict(model, dataloader):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Confusion Matrix 계산 함수\n",
    "def calculate_cm_metrics(y_pred, y_true):\n",
    "    # Confusion Matrix 계산\n",
    "    cm = confusion_matrix(y_true, y_pred)   # 매개변수 순서 : y축, x축\n",
    "\n",
    "    # 클래스별 TP, FN, FP, TN 값 계산\n",
    "    n = cm.shape[0]\n",
    "    precision = np.zeros(n)\n",
    "    recall = np.zeros(n)\n",
    "    f1_score = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        tp = tp = cm[i, i]\n",
    "        fn = cm[i].sum() - tp\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        tn = cm.sum() - tp - fn - fp\n",
    "\n",
    "        precision[i] = tp / (tp + fp)\n",
    "        recall[i] = tp / (tp + fn)\n",
    "        f1_score[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i])\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "# 모델 평가\n",
    "predictions, true_labels = predict(model, dataloaders['test'])\n",
    "\n",
    "# 평가 메트릭 계산\n",
    "acc, precision, recall, f1 = calculate_cm_metrics(predictions, true_labels)\n",
    "\n",
    "# 계산된 평가 메트릭 출력\n",
    "print('Accuracy = {:.2f}'.format(acc))\n",
    "print('Precision = {:.2f}'.format(precision[0]))\n",
    "print('Recall = {:.2f}'.format(recall[0]))\n",
    "print('f1-score = {:.2f}'.format(f1[0]))\n",
    "\n",
    "# scikit-learn 활용하여 평가 메트릭 계산\n",
    "print('\\nscikit-learn')\n",
    "print('Accuracy = {:.2f}'.format(accuracy_score(true_labels, predictions)))\n",
    "print('Precision = {:.2f}'.format(precision_score(true_labels, predictions, average=None)[0]))\n",
    "print('Recall = {:.2f}'.format(recall_score(true_labels, predictions, average=None)[0]))\n",
    "print('F1-score = {:.2f}'.format(f1_score(true_labels, predictions, average=None)[0]))\n",
    "\n",
    "# 혼동 행렬\n",
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    이 함수는 혼동 행렬을 표시합니다.\n",
    "    정규화를 사용하려면 'normalize=True'로 설정하십시오.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.4f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40621af4-3a56-4fea-85e7-5aeddc58174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plot_confusion_matrix(cm, classes=image_datasets['test'].classes, title='Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9406cd-8557-44a9-bd12-7c9bcde725d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###잔짜끝<>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
